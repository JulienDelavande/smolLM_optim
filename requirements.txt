transformers==4.45.2
torch
optimum[onnxruntime,intel,neural-compressor]==1.23.3
optimum-intel==1.21.0
onnxruntime==1.20.1
pyyaml
numpy
datasets==3.2.0
codecarbon==2.8.2
bitsandbytes==0.45.0
onnxruntime-gpu==1.20.1